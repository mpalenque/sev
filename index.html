<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>Skin Smoothing with MediaPipe ImageSegmenter</title>
<style>
  body {
    font-family: Arial, sans-serif;
    margin: 20px;
    display: flex;
    flex-direction: column;
    align-items: center;
    background-color: #f0f0f0;
    background-image: url('sev.png');
    background-size: cover; /* Optional: to make the image cover the entire background */
    background-repeat: no-repeat; /* Optional: to prevent the image from repeating */
    background-position: center center; /* Optional: to center the image */
  }
  #liveViewContainer {
    position: relative;
    border: 1px solid #ccc;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    background-color: transparent; /* Ensure this is transparent */
    padding: 10px;
    border-radius: 8px;
  }
  video {
    display: none; /* Hide video element, we'll draw to canvas */
  }
  canvas {
    display: block;
    border: 1px solid #ddd;
  }
  .controls {
    margin-top: 15px;
    padding: 15px;
    background-color: #fff;
    border-radius: 8px;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    display: flex;
    flex-direction: column;
    align-items: center;
  }
  .controls button {
    padding: 10px 15px;
    font-size: 16px;
    cursor: pointer;
    border: none;
    border-radius: 5px;
    background-color: #007bff;
    color: white;
    margin-bottom: 10px;
  }
  .controls button:hover {
    background-color: #0056b3;
  }
  .controls label {
    margin-bottom: 5px;
  }
  .controls input[type="range"] {
    width: 200px;
  }
  #loadingMessage {
    position: absolute;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    font-size: 1.2em;
    color: #333;
    background-color: rgba(255, 255, 255, 0.8);
    padding: 10px;
    border-radius: 5px;
    display: none; /* Hidden by default */
  }
</style>
</head>
<body>
  

  <div id="liveViewContainer">
    <video id="webcam" autoplay playsinline></video>
    <canvas id="output_canvas" width="640" height="480"></canvas>
    <div id="loadingMessage">Loading model and webcam...</div>
  </div>

  <div class="controls">
    <button id="webcamButton">ENABLE WEBCAM</button>
    <button id="takePhotoButton" style="margin-top: 10px;">TAKE PHOTO</button>
  </div>

  <script type="module">
    import vision from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3"; // Changed import style
    const { ImageSegmenter, FaceLandmarker, FilesetResolver } = vision; // Destructure necessary components

    let imageSegmenter;
    let faceLandmarker;
    let runningMode = "VIDEO";
    const video = document.getElementById("webcam");
    const canvasElement = document.getElementById("output_canvas");
    const canvasCtx = canvasElement.getContext("2d", { alpha: true });
    const webcamButton = document.getElementById("webcamButton");
    const loadingMessage = document.getElementById("loadingMessage");
    const takePhotoButton = document.getElementById("takePhotoButton");

    const blurScaleFactor = 0.5; 
    const landmarkMaskScaleFactor = 0.5; 
    const landmarkMaskBlurRadius = 3; 
    const SLIDER_POWER_CURVE = 3; 
    const RAW_SLIDER_DEFAULT_VALUE = 0.8; // New constant for the desired default raw value
    const SLIDER_MAX_VALUE = 20; // Original max value of the slider

    function calculateEffectiveBlur(rawValue, sliderMax, power) {
      if (sliderMax === 0) return 0; 
      const normalizedValue = rawValue / sliderMax;
      return Math.pow(normalizedValue, power) * sliderMax;
    }

    // Set blurAmount using the new default raw value
    let blurAmount = calculateEffectiveBlur(
      RAW_SLIDER_DEFAULT_VALUE,
      SLIDER_MAX_VALUE,
      SLIDER_POWER_CURVE
    );

    const blurredVideoCanvas = document.createElement("canvas");
    const blurredVideoCtx = blurredVideoCanvas.getContext("2d", { alpha: true });
    const maskCanvas = document.createElement("canvas");
    const maskCanvasCtx = maskCanvas.getContext("2d", { alpha: true });
    const effectLayerCanvas = document.createElement("canvas");
    const effectLayerCtx = effectLayerCanvas.getContext("2d", { alpha: true });

    const eyeMaskCanvas = document.createElement("canvas");
    const eyeMaskCtx = eyeMaskCanvas.getContext("2d", { alpha: true });

    const faceOvalMaskCanvas = document.createElement("canvas");
    const faceOvalMaskCtx = faceOvalMaskCanvas.getContext("2d", { alpha: true });

    let tempBlurLayerCanvas;
    let tempBlurLayerCtx;

    const personMaskCanvas = document.createElement("canvas");
    const personMaskCtx = personMaskCanvas.getContext("2d");
    const personOnlyCanvas = document.createElement("canvas");
    const personOnlyCtx = personOnlyCanvas.getContext("2d");

    const skinCategoryIndices = [3];
    const personCategoryIndices = [1, 2, 3, 4];

    async function createMediaPipeTasks() {
      loadingMessage.textContent = 'Initializing MediaPipe tasks...';
      loadingMessage.style.display = 'block';
      console.log("Attempting to create MediaPipe tasks...");
      let visionFilesetResolver;
      try {
        visionFilesetResolver = await FilesetResolver.forVisionTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"
        );
      } catch (e) {
        console.error("Failed to load FilesetResolver for Vision Tasks:", e);
        loadingMessage.textContent = 'Error: Could not load MediaPipe vision tasks. Check console.';
        return;
      }
      console.log("FilesetResolver loaded.");

      let imageSegmenterDelegate = "GPU";
      try {
        loadingMessage.textContent = 'Loading Image Segmenter model (GPU)...';
        const segmenterStartTime = performance.now();
        imageSegmenter = await ImageSegmenter.createFromOptions(visionFilesetResolver, {
          baseOptions: {
            modelAssetPath: "https://storage.googleapis.com/mediapipe-models/image_segmenter/selfie_multiclass_256x256/float32/latest/selfie_multiclass_256x256.tflite",
            delegate: "GPU"
          },
          runningMode: runningMode,
          outputCategoryMask: true,
          outputConfidenceMasks: false
        });
        const segmenterLoadTime = performance.now() - segmenterStartTime;
        console.log(`ImageSegmenter (GPU) created successfully in ${segmenterLoadTime.toFixed(2)}ms.`);
      } catch (gpuError) {
        console.warn("Failed to create ImageSegmenter with GPU delegate:", gpuError);
        imageSegmenterDelegate = "CPU";
        loadingMessage.textContent = 'GPU failed for Image Segmenter. Trying CPU...';
        try {
          const segmenterStartTime = performance.now();
          imageSegmenter = await ImageSegmenter.createFromOptions(visionFilesetResolver, {
            baseOptions: {
              modelAssetPath: "https://storage.googleapis.com/mediapipe-models/image_segmenter/selfie_multiclass_256x256/float32/latest/selfie_multiclass_256x256.tflite",
              delegate: "CPU"
            },
            runningMode: runningMode,
            outputCategoryMask: true,
            outputConfidenceMasks: false
          });
          const segmenterLoadTime = performance.now() - segmenterStartTime;
          console.log(`ImageSegmenter (CPU) created successfully in ${segmenterLoadTime.toFixed(2)}ms after GPU fallback.`);
        } catch (cpuError) {
          console.error("Failed to create ImageSegmenter with CPU delegate after GPU failure:", cpuError);
          loadingMessage.textContent = 'Error: Could not load Image Segmenter (GPU & CPU). Check console.';
          return;
        }
      }

      let faceLandmarkerDelegate = "GPU";
      try {
        loadingMessage.textContent = `Loading Face Landmarker model (GPU)... (Image Segmenter: ${imageSegmenterDelegate})`;
        const landmarkerStartTime = performance.now();
        faceLandmarker = await FaceLandmarker.createFromOptions(visionFilesetResolver, {
          baseOptions: {
            modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`,
            delegate: "GPU"
          },
          outputFaceBlendshapes: false,
          outputFacialTransformationMatrixes: false,
          runningMode: runningMode,
          numFaces: 1
        });
        const landmarkerLoadTime = performance.now() - landmarkerStartTime;
        console.log(`FaceLandmarker (GPU) created successfully in ${landmarkerLoadTime.toFixed(2)}ms.`);
      } catch (gpuError) {
        console.warn("Failed to create FaceLandmarker with GPU delegate:", gpuError);
        faceLandmarkerDelegate = "CPU";
        loadingMessage.textContent = `GPU failed for Face Landmarker. Trying CPU... (Image Segmenter: ${imageSegmenterDelegate})`;
        try {
          const landmarkerStartTime = performance.now();
          faceLandmarker = await FaceLandmarker.createFromOptions(visionFilesetResolver, {
            baseOptions: {
              modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`,
              delegate: "CPU"
            },
            outputFaceBlendshapes: false,
            outputFacialTransformationMatrixes: false,
            runningMode: runningMode,
            numFaces: 1
          });
          const landmarkerLoadTime = performance.now() - landmarkerStartTime;
          console.log(`FaceLandmarker (CPU) created successfully in ${landmarkerLoadTime.toFixed(2)}ms after GPU fallback.`);
        } catch (cpuError) {
          console.error("Failed to create FaceLandmarker with CPU delegate after GPU failure:", cpuError);
          loadingMessage.textContent = `Error: Could not load Face Landmarker (GPU & CPU). Image Segmenter: ${imageSegmenterDelegate}. Check console.`;
          return;
        }
      }
      
      loadingMessage.textContent = `Models loaded (Segmenter: ${imageSegmenterDelegate}, Landmarker: ${faceLandmarkerDelegate}).`;
      setTimeout(() => {
          if (loadingMessage.textContent === `Models loaded (Segmenter: ${imageSegmenterDelegate}, Landmarker: ${faceLandmarkerDelegate}).`) {
            loadingMessage.style.display = 'none';
          }
      }, 1500); // Increased timeout slightly
    }

    async function enableCam() {
      if (!imageSegmenter || !faceLandmarker) {
        loadingMessage.textContent = 'Models not yet loaded. Please wait...';
        loadingMessage.style.display = 'block';
        await createMediaPipeTasks();
        if (!imageSegmenter || !faceLandmarker) {
            console.error("MediaPipe tasks failed to initialize. Cannot enable webcam features.");
            webcamButton.disabled = false;
            return;
        }
      }

      if (webcamButton.textContent === "ENABLE WEBCAM") {
        webcamButton.disabled = true;
        loadingMessage.textContent = 'Accessing webcam...';
        loadingMessage.style.display = 'block';
        const constraints = { video: true };
        try {
          const stream = await navigator.mediaDevices.getUserMedia(constraints);
          video.srcObject = stream;
          
          const startPredictionLogic = () => {
            console.log(`Video 'playing' event fired. Raw dimensions: ${video.videoWidth}x${video.videoHeight}`);
            video.removeEventListener("playing", startPredictionLogic);

            if (video.videoWidth === 0 || video.videoHeight === 0) {
                console.error("CRITICAL: Video dimensions are zero at 'playing' event. Effect will likely fail.");
                loadingMessage.textContent = 'Error: Video stream has zero dimensions.';
                loadingMessage.style.display = 'block';
                webcamButton.disabled = false;
                isPredicting = false; 
                return;
            }
            
            canvasElement.width = video.videoWidth;
            canvasElement.height = video.videoHeight;
            
            blurredVideoCanvas.width = video.videoWidth * blurScaleFactor;
            blurredVideoCanvas.height = video.videoHeight * blurScaleFactor;
            
            effectLayerCanvas.width = video.videoWidth;
            effectLayerCanvas.height = video.videoHeight;
            eyeMaskCanvas.width = video.videoWidth * landmarkMaskScaleFactor; 
            eyeMaskCanvas.height = video.videoHeight * landmarkMaskScaleFactor; 
            faceOvalMaskCanvas.width = video.videoWidth * landmarkMaskScaleFactor; 
            faceOvalMaskCanvas.height = video.videoHeight * landmarkMaskScaleFactor; 

            personOnlyCanvas.width = video.videoWidth;
            personOnlyCanvas.height = video.videoHeight;

            if (!tempBlurLayerCanvas) {
                tempBlurLayerCanvas = document.createElement('canvas');
                tempBlurLayerCtx = tempBlurLayerCanvas.getContext('2d');
            }
            tempBlurLayerCanvas.width = video.videoWidth;
            tempBlurLayerCanvas.height = video.videoHeight;

            loadingMessage.style.display = 'none';
            webcamButton.textContent = "DISABLE WEBCAM";
            webcamButton.disabled = false;
            
            console.log("[startPredictionLogic] Setting isPredicting = true.");
            isPredicting = true; 
            console.log("[startPredictionLogic] Calling predictWebcam for the first time.");
            predictWebcam();
          };

          video.addEventListener("playing", startPredictionLogic);
          
          video.play().then(() => {
            console.log("Video play() promise resolved. Playback should be starting or started.");
          }).catch(e => {
            console.error("Video play failed:", e);
            loadingMessage.textContent = 'Error playing video. Check permissions.';
            webcamButton.disabled = false;
            video.removeEventListener("playing", startPredictionLogic); 
          });

        } catch (err) {
          console.error("Error accessing webcam: ", err);
          loadingMessage.textContent = 'Error accessing webcam. Please allow access and try again.';
          webcamButton.disabled = false;
        }
      } else {
        video.srcObject.getTracks().forEach(track => track.stop());
        video.srcObject = null;
        webcamButton.textContent = "ENABLE WEBCAM";
        canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
        isPredicting = false;
      }
    }
    webcamButton.addEventListener("click", enableCam);

    async function dataURLtoBlob(dataurl) {
      const res = await fetch(dataurl);
      return await res.blob();
    }

    async function handleTakePhotoClick() {
      if (!isPredicting || !video.srcObject || video.paused || video.ended) {
        alert("Please enable the webcam and ensure it's active before taking a photo.");
        return;
      }
      if (canvasElement.width === 0 || canvasElement.height === 0) {
        alert("Canvas dimensions are zero. Cannot take photo. Please ensure webcam is properly initialized.");
        return;
      }

      try {
        const photoCanvas = document.createElement('canvas');
        photoCanvas.width = canvasElement.width;
        photoCanvas.height = canvasElement.height;
        const photoCtx = photoCanvas.getContext('2d');

        const dataUrl = await new Promise((resolve, reject) => {
          const backgroundImage = new Image();
          backgroundImage.src = 'sev.png';

          backgroundImage.onload = () => {
            const cw = photoCanvas.width;
            const ch = photoCanvas.height;
            const iw = backgroundImage.naturalWidth;
            const ih = backgroundImage.naturalHeight;

            const canvasRatio = cw / ch;
            const imageRatio = iw / ih;

            let dx = 0, dy = 0, dWidth = 0, dHeight = 0;

            if (canvasRatio > imageRatio) {
              dHeight = ch;
              dWidth = iw * (ch / ih);
              dx = (cw - dWidth) / 2;
              dy = 0;
            } else {
              dWidth = cw;
              dHeight = ih * (cw / iw);
              dx = 0;
              dy = (ch - dHeight) / 2;
            }

            photoCtx.drawImage(backgroundImage, dx, dy, dWidth, dHeight);

            photoCtx.drawImage(canvasElement, 0, 0, cw, ch);

            resolve(photoCanvas.toDataURL("image/png"));
          };

          backgroundImage.onerror = (err) => {
            console.error("Error loading background image 'sev.png'. Proceeding without custom background.", err);
            photoCtx.drawImage(canvasElement, 0, 0, photoCanvas.width, photoCanvas.height);
            resolve(photoCanvas.toDataURL("image/png"));
          };
        });

        const blob = await dataURLtoBlob(dataUrl);
        const fileName = "photo.png";
        const file = new File([blob], fileName, { type: "image/png" });
        
        const shareData = {
          files: [file],
          title: "My Photo",
          text: "Check out this photo I took!",
        };

        if (navigator.share && navigator.canShare && navigator.canShare(shareData)) {
          await navigator.share(shareData);
          console.log("Photo shared successfully or share dialog opened.");
        } else {
          console.warn("Web Share API not supported or cannot share this data. Falling back to download.");
          const link = document.createElement("a");
          link.href = dataUrl;
          link.download = fileName;
          document.body.appendChild(link);
          link.click();
          document.body.removeChild(link);
          alert("Photo downloaded as Web Share is not available.");
        }
      } catch (error) {
        console.error("Error taking or sharing photo:", error);
        alert(`Error: ${error.message}`);
        if (error.name !== 'AbortError') {
            const dataUrl = canvasElement.toDataURL("image/png");
            const link = document.createElement("a");
            link.href = dataUrl;
            link.download = "photo_fallback.png";
            document.body.appendChild(link);
            link.click();
            document.body.removeChild(link);
            alert("Sharing failed. Photo downloaded instead.");
        }
      }
    }

    takePhotoButton.addEventListener("click", handleTakePhotoClick);

    function drawMaskFromPixelData(maskPixelData, maskWidth, maskHeight, targetCtx, targetIndices) {
      if (!maskPixelData || maskPixelData.length === 0) {
        console.error("Invalid or empty maskPixelData received in drawMaskFromPixelData");
        targetCtx.clearRect(0, 0, targetCtx.canvas.width, targetCtx.canvas.height);
        return;
      }
      
      if (targetCtx.canvas.width !== maskWidth || targetCtx.canvas.height !== maskHeight) {
          targetCtx.canvas.width = maskWidth;
          targetCtx.canvas.height = maskHeight;
      }

      const newImageData = targetCtx.createImageData(maskWidth, maskHeight);
      const newPixelData = newImageData.data; 

      if (maskPixelData.length !== maskWidth * maskHeight) {
          console.error(`maskPixelData.length (${maskPixelData.length}) does not match maskWidth*maskHeight (${maskWidth*maskHeight}).`);
          targetCtx.clearRect(0, 0, targetCtx.canvas.width, targetCtx.canvas.height);
          return;
      }

      for (let i = 0; i < maskPixelData.length; i++) {
        const category = maskPixelData[i];
        const offset = i * 4;
        if (targetIndices.includes(category)) {
          newPixelData[offset] = 0;     // R (can be any color, alpha is key)
          newPixelData[offset + 1] = 0; // G
          newPixelData[offset + 2] = 0; // B
          newPixelData[offset + 3] = 255; // Alpha: Opaque for skin
        } else {
          newPixelData[offset + 3] = 0;   // Alpha: Transparent for non-skin
        }
      }
      targetCtx.putImageData(newImageData, 0, 0);
    }

    let lastVideoTime = -1;
    let isPredicting = false;

    async function predictWebcam() {
      console.log(`[predictWebcam START] isPredicting: ${isPredicting}, video.paused: ${video.paused}, video.ended: ${video.ended}, video.readyState: ${video.readyState}, blurAmount: ${blurAmount}`);

      if (!isPredicting || !video.srcObject || video.paused || video.ended) {
        isPredicting = false;
        console.log("[predictWebcam] Loop stopping: initial check failed (not predicting, no src, paused, or ended).");
        return;
      }

      if (video.readyState < video.HAVE_ENOUGH_DATA || !imageSegmenter || !faceLandmarker) {
          console.log(`[predictWebcam] Video not ready (readyState ${video.readyState}) or models not loaded. Retrying next frame.`);
          if (isPredicting) requestAnimationFrame(predictWebcam);
          return;
      }

      let startTimeMs = performance.now();
      let segmentationResultsToClose = null;

      if (video.currentTime !== lastVideoTime) {
        lastVideoTime = video.currentTime;
        
        const segmentationResults = imageSegmenter.segmentForVideo(video, startTimeMs);
        if (segmentationResults && segmentationResults.categoryMask) {
            segmentationResultsToClose = segmentationResults.categoryMask;
        }
        console.log("Segmentation results:", segmentationResults);
        const landmarkResults = faceLandmarker.detectForVideo(video, startTimeMs);
        console.log("Landmark results:", landmarkResults);

        canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

        let personDrawnSuccessfully = false;
        if (segmentationResults && segmentationResults.categoryMask) {
          const fullMask = segmentationResults.categoryMask;
          const fullMaskPixelData = fullMask.getAsUint8Array();
          const fullMaskWidth = fullMask.width;
          const fullMaskHeight = fullMask.height;

          if (fullMaskPixelData && fullMaskWidth > 0 && fullMaskHeight > 0) {
            if (personMaskCanvas.width !== fullMaskWidth || personMaskCanvas.height !== fullMaskHeight) {
              personMaskCanvas.width = fullMaskWidth;
              personMaskCanvas.height = fullMaskHeight;
            }
            drawMaskFromPixelData(fullMaskPixelData, fullMaskWidth, fullMaskHeight, personMaskCtx, personCategoryIndices);

            personOnlyCtx.clearRect(0, 0, personOnlyCanvas.width, personOnlyCanvas.height);
            personOnlyCtx.drawImage(video, 0, 0, personOnlyCanvas.width, personOnlyCanvas.height);
            personOnlyCtx.globalCompositeOperation = 'destination-in';
            personOnlyCtx.drawImage(personMaskCanvas, 0, 0, personOnlyCanvas.width, personOnlyCanvas.height);
            personOnlyCtx.globalCompositeOperation = 'source-over';

            canvasCtx.drawImage(personOnlyCanvas, 0, 0, canvasElement.width, canvasElement.height);
            personDrawnSuccessfully = true;
          }
        }

        if (!personDrawnSuccessfully) {
          console.warn("[predictWebcam] Person segmentation failed or no mask. Drawing raw video.");
          canvasCtx.drawImage(video, 0, 0, canvasElement.width, canvasElement.height);
        }

        if (segmentationResults && segmentationResults.categoryMask && landmarkResults && landmarkResults.faceLandmarks && landmarkResults.faceLandmarks.length > 0) {
          console.log("CategoryMask available for smoothing:", !!segmentationResults.categoryMask);
          console.log("FaceLandmarks available for smoothing:", landmarkResults.faceLandmarks.length);
          const skinMaskForSmoothing = segmentationResults.categoryMask;
          const skinMaskPixelData = skinMaskForSmoothing.getAsUint8Array();
          const skinMaskWidth = skinMaskForSmoothing.width;
          const skinMaskHeight = skinMaskForSmoothing.height;
          const landmarks = landmarkResults.faceLandmarks[0];
          console.log(`Skin mask dimensions for smoothing: ${skinMaskWidth}x${skinMaskHeight}. Pixel data length: ${skinMaskPixelData ? skinMaskPixelData.length : 'null'}`);

          if (skinMaskPixelData && skinMaskWidth > 0 && skinMaskHeight > 0) {
            blurredVideoCtx.clearRect(0, 0, blurredVideoCanvas.width, blurredVideoCanvas.height);
            const originalFilterBlurredVideo = blurredVideoCtx.filter;
            if (blurAmount > 0) {
                blurredVideoCtx.filter = `blur(${blurAmount}px)`;
            } else {
                blurredVideoCtx.filter = 'none';
            }
            blurredVideoCtx.drawImage(video, 0, 0, blurredVideoCanvas.width, blurredVideoCanvas.height);
            blurredVideoCtx.filter = originalFilterBlurredVideo;

            if (maskCanvas.width !== skinMaskWidth || maskCanvas.height !== skinMaskHeight) {
                maskCanvas.width = skinMaskWidth;
                maskCanvas.height = skinMaskHeight;
            }
            drawMaskFromPixelData(skinMaskPixelData, skinMaskWidth, skinMaskHeight, maskCanvasCtx, skinCategoryIndices);

            eyeMaskCtx.clearRect(0, 0, eyeMaskCanvas.width, eyeMaskCanvas.height);
            eyeMaskCtx.fillStyle = 'white';
            
            const originalFilterEye = eyeMaskCtx.filter;
            if (landmarkMaskBlurRadius > 0) {
                eyeMaskCtx.filter = `blur(${landmarkMaskBlurRadius}px)`;
            }

            function drawLandmarkPolygon(landmarkConnections, targetCtx, targetCanvas) {
              if (landmarks && landmarkConnections && landmarkConnections.length > 0) {
                targetCtx.beginPath();
                const firstLandmarkIndex = landmarkConnections[0].start;
                if (landmarks[firstLandmarkIndex]) {
                  const firstPoint = landmarks[firstLandmarkIndex];
                  targetCtx.moveTo(firstPoint.x * targetCanvas.width, firstPoint.y * targetCanvas.height);
                  for (const conn of landmarkConnections) {
                    const endLandmarkIndex = conn.end;
                    if (landmarks[endLandmarkIndex]) {
                      const endPoint = landmarks[endLandmarkIndex];
                      targetCtx.lineTo(endPoint.x * targetCanvas.width, endPoint.y * targetCanvas.height);
                    } else {
                      console.warn(`Landmark index ${endLandmarkIndex} not found.`);
                    }
                  }
                  targetCtx.closePath();
                  targetCtx.fill();
                } else {
                  console.warn(`Landmark index ${firstLandmarkIndex} not found for starting point.`);
                }
              }
            }

            function drawCustomLandmarkPolygonFromIndices(vertexIndices, targetCtx, targetCanvas) {
              if (landmarks && vertexIndices && vertexIndices.length > 0) {
                targetCtx.beginPath();
                const firstLandmarkIndex = vertexIndices[0];
                if (landmarks[firstLandmarkIndex]) {
                  const firstPoint = landmarks[firstLandmarkIndex];
                  targetCtx.moveTo(firstPoint.x * targetCanvas.width, firstPoint.y * targetCanvas.height);
                  for (let i = 1; i < vertexIndices.length; i++) {
                    const landmarkIndex = vertexIndices[i];
                    if (landmarks[landmarkIndex]) {
                      const point = landmarks[landmarkIndex];
                      targetCtx.lineTo(point.x * targetCanvas.width, point.y * targetCanvas.height);
                    } else {
                      console.warn(`Landmark index ${landmarkIndex} not found in custom list.`);
                    }
                  }
                  targetCtx.closePath();
                  targetCtx.fill();
                } else {
                  console.warn(`Landmark index ${firstLandmarkIndex} not found for starting point in custom list.`);
                }
              }
            }

            function drawTriangleOnMask(vertexIndices, targetCtx, targetCanvas) {
              if (landmarks && vertexIndices && vertexIndices.length === 3) {
                const points = vertexIndices.map(index => landmarks[index]);
                if (points.every(p => p)) {
                  targetCtx.beginPath();
                  targetCtx.moveTo(points[0].x * targetCanvas.width, points[0].y * targetCanvas.height);
                  targetCtx.lineTo(points[1].x * targetCanvas.width, points[1].y * targetCanvas.height);
                  targetCtx.lineTo(points[2].x * targetCanvas.width, points[2].y * targetCanvas.height);
                  targetCtx.closePath();
                  targetCtx.fill();
                } else {
                  console.warn(`Invalid landmark index in triangle: ${vertexIndices}`);
                }
              }
            }

            drawLandmarkPolygon(FaceLandmarker.FACE_LANDMARKS_LEFT_EYE, eyeMaskCtx, eyeMaskCanvas);
            drawLandmarkPolygon(FaceLandmarker.FACE_LANDMARKS_RIGHT_EYE, eyeMaskCtx, eyeMaskCanvas);
            drawLandmarkPolygon(FaceLandmarker.FACE_LANDMARKS_LEFT_EYEBROW, eyeMaskCtx, eyeMaskCanvas);
            drawLandmarkPolygon(FaceLandmarker.FACE_LANDMARKS_RIGHT_EYEBROW, eyeMaskCtx, eyeMaskCanvas);
            drawLandmarkPolygon(FaceLandmarker.FACE_LANDMARKS_LIPS, eyeMaskCtx, eyeMaskCanvas);

            const innerMouthTriangles = [
              [78, 95, 88], [78, 178, 87], [95, 178, 96],
              [78, 88, 87], [88, 87, 178], [88, 95, 96],
              [96, 88, 178]
            ];
            innerMouthTriangles.forEach(triangle => drawTriangleOnMask(triangle, eyeMaskCtx, eyeMaskCanvas));
            drawTriangleOnMask([185, 292, 61], eyeMaskCtx, eyeMaskCanvas);
            const specificEyebrowTriangles = [
              [107, 55, 65], [63, 46, 52],
              [336, 285, 295], [293, 276, 334]
            ];
            specificEyebrowTriangles.forEach(triangle => drawTriangleOnMask(triangle, eyeMaskCtx, eyeMaskCanvas));

            const additionalEyeVertices = [7,22,23,24,25,26,27,28,29,30,33,56,110,112,130,133,144,145,153,154,155,157,158,159,160,161,163,173,190,243,246,247];
            drawCustomLandmarkPolygonFromIndices(additionalEyeVertices, eyeMaskCtx, eyeMaskCanvas);

            const additionalOtherEyeVertices = [249,252,253,254,255,256,257,258,259,260,263,286,339,341,359,362,373,374,380,381,382,384,385,386,387,388,390,398,414,463,466,467];
            drawCustomLandmarkPolygonFromIndices(additionalOtherEyeVertices, eyeMaskCtx, eyeMaskCanvas);

            eyeMaskCtx.filter = originalFilterEye;

            faceOvalMaskCtx.clearRect(0, 0, faceOvalMaskCanvas.width, faceOvalMaskCanvas.height);
            faceOvalMaskCtx.fillStyle = 'white';
            
            const originalFilterOval = faceOvalMaskCtx.filter;
            if (landmarkMaskBlurRadius > 0) {
                faceOvalMaskCtx.filter = `blur(${landmarkMaskBlurRadius}px)`;
            }
            drawLandmarkPolygon(FaceLandmarker.FACE_LANDMARKS_FACE_OVAL, faceOvalMaskCtx, faceOvalMaskCanvas);
            faceOvalMaskCtx.filter = originalFilterOval;

            effectLayerCtx.clearRect(0, 0, effectLayerCanvas.width, effectLayerCanvas.height);
            effectLayerCtx.drawImage(maskCanvas, 0, 0, effectLayerCanvas.width, effectLayerCanvas.height);
            
            effectLayerCtx.globalCompositeOperation = 'destination-in';
            effectLayerCtx.drawImage(faceOvalMaskCanvas, 0, 0, effectLayerCanvas.width, effectLayerCanvas.height);
            
            effectLayerCtx.globalCompositeOperation = 'destination-out';
            effectLayerCtx.drawImage(eyeMaskCanvas, 0, 0, effectLayerCanvas.width, effectLayerCanvas.height);
            
            effectLayerCtx.globalCompositeOperation = 'source-over';

            tempBlurLayerCtx.clearRect(0, 0, tempBlurLayerCanvas.width, tempBlurLayerCanvas.height);

            tempBlurLayerCtx.drawImage(blurredVideoCanvas, 0, 0, tempBlurLayerCanvas.width, tempBlurLayerCanvas.height);
            tempBlurLayerCtx.globalCompositeOperation = 'destination-in';
            tempBlurLayerCtx.drawImage(effectLayerCanvas, 0, 0, tempBlurLayerCanvas.width, tempBlurLayerCanvas.height);
            tempBlurLayerCtx.globalCompositeOperation = 'source-over';

            canvasCtx.drawImage(tempBlurLayerCanvas, 0, 0);

          } else {
            console.warn("[predictWebcam] Skin mask data for smoothing was invalid or dimensions were zero. Skipping smoothing effect.");
          }
        } else {
            console.warn("[predictWebcam] No valid segmentation mask OR no landmarks found for this frame. Skipping smoothing effect.");
        }
      }
      
      if(segmentationResultsToClose){
        try {
            segmentationResultsToClose.close();
        } catch(e){
            console.warn("Error closing categoryMask:", e);
        }
      }

      if (isPredicting) {
        window.requestAnimationFrame(predictWebcam);
      } else {
        console.log("[predictWebcam END] Not predicting, loop will stop.");
      }
    }
  </script>
</body>
</html>
